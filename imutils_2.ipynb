{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(r'C:\\Users\\knataraj\\Desktop\\swan.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Translate or Shift or Move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift the image\n",
    "# positive value  - right and down\n",
    "# negative value - left and up\n",
    "def translate(image, x, y):\n",
    "    \n",
    "    matrix = np.float32([[1,0,x],[0,1,y]])\n",
    "    shifted = cv2.warpAffine(image, matrix, (image.shape[1], image.shape[0]))\n",
    "    return shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example for translating/shifting an image\n",
    "\n",
    "shifted = translate(image, -100, -100)\n",
    "\n",
    "cv2.namedWindow('shifted', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('shifted', shifted)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotate an image\n",
    "\n",
    "def rotation(image, angle, center = None, scale = 1):\n",
    "    (h,w) = image.shape[:2]\n",
    "    if center is None:\n",
    "        center = (w//2, h//2)\n",
    "    \n",
    "    matrix = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    rotated = cv2.warpAffine(image, matrix, (w,h))\n",
    "    return rotated\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example for rotating an image\n",
    "\n",
    "image = cv2.imread(r'C:\\Users\\knataraj\\Desktop\\swan.jpg')\n",
    "\n",
    "rotated = rotation(image, 180, scale = 1)\n",
    "\n",
    "cv2.namedWindow('rotated', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('rotated', rotated)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize an image - pixel reduction!?\n",
    "\n",
    "def resize(image, width = None, height = None, interpolation = cv2.INTER_AREA):\n",
    "    \n",
    "    dimension = None\n",
    "    (h, w) = image.shape[:2] \n",
    "    \n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    \n",
    "    if width is None:\n",
    "        ratio = height / float(h)\n",
    "        dimension = (int(w*ratio), height)\n",
    "    else:\n",
    "        ratio = width / float(w)\n",
    "        dimension = (width, int(h * ratio))\n",
    "        \n",
    "    resized = cv2.resize(image, dimension, interpolation = interpolation)\n",
    "    return resized\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example for resizing an image\n",
    "\n",
    "image = cv2.imread(r'C:\\Users\\knataraj\\Desktop\\swan.jpg')\n",
    "\n",
    "resized = resize(image, width = 180, height = 200)\n",
    "\n",
    "#cv2.namedWindow('resized', cv2.WINDOW_NORMAL) - to view resized image\n",
    "cv2.imshow('resized', resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip an image\n",
    "\n",
    "# horizontal flip = 1\n",
    "# vertical flip = 0\n",
    "# horizontal and vertical flip = -1\n",
    "\n",
    "image = cv2.imread(r'C:\\Users\\knataraj\\Desktop\\swan.jpg')\n",
    "\n",
    "flipped = cv2.flip(image, 1)\n",
    "\n",
    "#cv2.namedWindow('resized', cv2.WINDOW_NORMAL) - to view resized image\n",
    "cv2.imshow('flipped', flipped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# croping an image by slicing\n",
    "# image[yStart:yEnd, xStart:xEnd]\n",
    "\n",
    "#  y0,x0------------xn\n",
    "#   |\n",
    "#   |\n",
    "#   |\n",
    "#   |\n",
    "#   |\n",
    "#   |\n",
    "#   yn\n",
    "\n",
    "image = cv2.imread(r'C:\\Users\\knataraj\\Desktop\\swan.jpg')\n",
    "\n",
    "cropped = image[100:700, 400:900] # image[yStart : yEnd, xStart : xEnd] # image[y,x]\n",
    "\n",
    "#cv2.namedWindow('resized', cv2.WINDOW_NORMAL) - to view resized image\n",
    "cv2.imshow('cropped', cropped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### translate -> create a matrix, specify x and y \n",
    "###### rotate -> create a matrix, input the angle, find the center, specify the scale\n",
    "###### resize -> find ratio and dimention, specify interpolation\n",
    "###### flip -> 1 = horizontal flip, 0 = vertical flip, -1 = both\n",
    "###### crop -> [yStart:yEnd, xStart: xEnd]   image[y,x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Arithmetic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding pixel values to the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brightness to the image\n",
    "\n",
    "matrix = np.ones(image.shape, dtype = 'uint8') * 100\n",
    "added = cv2.add(image, matrix)\n",
    "\n",
    "cv2.imshow('added', added)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# darkness to the image\n",
    "\n",
    "matrix = np.ones(image.shape, dtype = 'uint8') * 100\n",
    "added = cv2.subtract(image, matrix)\n",
    "\n",
    "cv2.imshow('added', added)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = cv2.imread(r'C:\\Users\\knataraj\\Desktop\\swan.jpg')\n",
    "\n",
    "image2 = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "blurred = cv2.GaussianBlur(image2, (5,5), 0)\n",
    "\n",
    "cv2.namedWindow('blurred', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('blurred', blurred)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(T, threshold1) = cv2.threshold(blurred, 90, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "cv2.namedWindow('threshold1', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('threshold1', threshold1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Masking on original image to view only interested area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('bird', cv2.bitwise_and(image1, image1, mask = threshold1))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaThresh1 = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 4)\n",
    "cv2.imshow('adaThresh', adaThresh1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaThresh2 = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 15, 3)\n",
    "cv2.imshow('adaThresh2', adaThresh2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradients & Edge detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageGrad = cv2.imread(r'C:\\Users\\knataraj\\Desktop\\swan.jpg')\n",
    "imageGradGray = cv2.cvtColor(imageGrad, cv2.COLOR_BGR2GRAY)\n",
    "lap = cv2.Laplacian(imageGradGray, cv2.CV_64F)\n",
    "lap = np.uint8(np.absolute(lap))\n",
    "cv2.imshow('lap', lap)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sobel - Noisy! - Let's use Canny Edge detector!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageSobel = cv2.imread(r'C:\\Users\\knataraj\\Desktop\\swan.jpg')\n",
    "imageSobel = cv2.cvtColor(imageSobel, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "sobelX = cv2.Sobel(imageSobel, cv2.CV_64F, 1,0)\n",
    "sobelY = cv2.Sobel(imageSobel, cv2.CV_64F, 0,1)\n",
    "\n",
    "sobelX = np.uint8(np.absolute(sobelX))\n",
    "sobelY = np.uint8(np.absolute(sobelY))\n",
    "\n",
    "sobelCombined = cv2.bitwise_or(sobelX, sobelY)\n",
    "\n",
    "cv2.imshow('sobelCombined', sobelCombined)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canny Edge Detector = blur + sobel + threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Canny edge detector is a multi-step process. It involves blurring the image to remove noise, computing Sobel gradient images in the x and y direction, suppressing edges, and ﬁnally a hysteresis thresholding stage that determines if a pixel is “edge-like” or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageEdge = cv2.imread(r'C:\\Users\\knataraj\\Desktop\\swan.jpg')\n",
    "imageEdgeGray = cv2.cvtColor(imageEdge, cv2.COLOR_BGR2GRAY)\n",
    "imageEdgeGrayBlur = cv2.GaussianBlur(imageEdgeGray, (5,5), 0)\n",
    "\n",
    "\n",
    "imageCanny = cv2.Canny(imageEdgeGrayBlur, 60, 120)\n",
    "\n",
    "# anything lessthan 60 is not an edge\n",
    "# anything greaterthan 120 is an edge\n",
    "# values between these two is classified based on how their intensities are connected\n",
    "\n",
    "cv2.imshow('imageCanny', imageCanny)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contours = curve points with no gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of contours are 13\n"
     ]
    }
   ],
   "source": [
    "imageCont = cv2.imread(r'C:\\Users\\knataraj\\Desktop\\swan.jpg')\n",
    "imageContGray = cv2.cvtColor(imageCont, cv2.COLOR_BGR2GRAY)\n",
    "imageContGrayBlur = cv2.GaussianBlur(imageContGray, (5,5), 0)\n",
    "imageContGrayBlurCanny = cv2.Canny(imageContGrayBlur, 10, 400)\n",
    "\n",
    "\n",
    "(cnts, _) = cv2.findContours(imageContGrayBlurCanny.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "print('Number of contours are {}'.format(len(cnts)))\n",
    "\n",
    "\n",
    "birdCont = imageCont.copy()\n",
    "cv2.drawContours(birdCont, cnts, -1, (0,255,0), 1)\n",
    "# -1 = draw all contours \n",
    "# positive numbers 1,2,3.. = draw specific contours\n",
    "\n",
    "cv2.imshow('birdCont', birdCont)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, c in enumerate(cnts):\n",
    "    \n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    birdCont = imageCont[y:y+h, x:x+w]\n",
    "    cv2.imshow('birdCont', birdCont)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
